{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fa73460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported to repositories.csv successfully.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "\n",
    "access_token = \"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\"\n",
    "\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {access_token}',\n",
    "    'Accept': 'application/vnd.github.v3+json'\n",
    "}\n",
    "\n",
    "query_params = {\n",
    "    'q': 'created:2023',  # Update the search query to match your desired criteria\n",
    "    'sort': 'stars',\n",
    "    'order': 'desc',\n",
    "    'per_page': 100,  # Number of results per page\n",
    "    'page': 1  # Initial page number\n",
    "}\n",
    "\n",
    "base_url = 'https://api.github.com/search/repositories'\n",
    "\n",
    "total_results = 0\n",
    "extracted_data = []\n",
    "\n",
    "while len(extracted_data) < 1000:  # Retrieve at least 1000 repositories\n",
    "    response = requests.get(base_url, headers=headers, params=query_params)\n",
    "    data = response.json()\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        repositories = data['items']\n",
    "\n",
    "        for repo in repositories:\n",
    "            name = repo['name']\n",
    "            url = repo['html_url']\n",
    "            language = repo['language'] if repo['language'] else 'N/A'\n",
    "            stars = repo['stargazers_count']\n",
    "            forks = repo['forks_count']\n",
    "            extracted_data.append({'Name': name, 'URL': url, 'Language': language, 'Stars': stars, 'Forks': forks})\n",
    "\n",
    "        total_results = data['total_count']\n",
    "\n",
    "        if len(repositories) == 0 or len(extracted_data) >= total_results:\n",
    "            break\n",
    "\n",
    "        query_params['page'] += 1\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data. Status code: {response.status_code}\")\n",
    "        break\n",
    "\n",
    "if len(extracted_data) > 0:\n",
    "    # Define the CSV file path\n",
    "    csv_file_path = 'repositories.csv'\n",
    "\n",
    "    # Write the data to the CSV file\n",
    "    with open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=['Name', 'URL', 'Language', 'Stars', 'Forks'])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(extracted_data)\n",
    "\n",
    "    print(f\"Data exported to {csv_file_path} successfully.\")\n",
    "else:\n",
    "    print(\"No data found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de3679f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa574040",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitExceededException",
     "evalue": "403 {\"documentation_url\": \"https://docs.github.com/en/free-pro-team@latest/rest/overview/resources-in-the-rest-api#secondary-rate-limits\", \"message\": \"You have exceeded a secondary rate limit. Please wait a few minutes before you try again.\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitExceededException\u001b[0m                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 18\u001b[0m\n\u001b[0;32m     14\u001b[0m repositories \u001b[38;5;241m=\u001b[39m g\u001b[38;5;241m.\u001b[39msearch_repositories(query, sort, order)\n\u001b[0;32m     16\u001b[0m extracted_data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m repo \u001b[38;5;129;01min\u001b[39;00m repositories:\n\u001b[0;32m     19\u001b[0m     name \u001b[38;5;241m=\u001b[39m repo\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m     20\u001b[0m     url \u001b[38;5;241m=\u001b[39m repo\u001b[38;5;241m.\u001b[39mhtml_url\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\data_dev\\Lib\\site-packages\\github\\PaginatedList.py:56\u001b[0m, in \u001b[0;36mPaginatedListBase.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__elements\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_couldGrow():\n\u001b[1;32m---> 56\u001b[0m     newElements \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m newElements\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\data_dev\\Lib\\site-packages\\github\\PaginatedList.py:67\u001b[0m, in \u001b[0;36mPaginatedListBase._grow\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_grow\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 67\u001b[0m     newElements \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fetchNextPage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__elements \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m newElements\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m newElements\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\data_dev\\Lib\\site-packages\\github\\PaginatedList.py:201\u001b[0m, in \u001b[0;36mPaginatedList._fetchNextPage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fetchNextPage\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 201\u001b[0m     headers, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__requester\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequestJsonAndCheck\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__nextUrl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__nextParams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__headers\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m     data \u001b[38;5;241m=\u001b[39m data \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__nextUrl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\data_dev\\Lib\\site-packages\\github\\Requester.py:398\u001b[0m, in \u001b[0;36mRequester.requestJsonAndCheck\u001b[1;34m(self, verb, url, parameters, headers, input)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequestJsonAndCheck\u001b[39m(\u001b[38;5;28mself\u001b[39m, verb, url, parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__check\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequestJson\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__customConnection\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\data_dev\\Lib\\site-packages\\github\\Requester.py:423\u001b[0m, in \u001b[0;36mRequester.__check\u001b[1;34m(self, status, responseHeaders, output)\u001b[0m\n\u001b[0;32m    421\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__structuredFromJson(output)\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m400\u001b[39m:\n\u001b[1;32m--> 423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__createException(status, responseHeaders, output)\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m responseHeaders, output\n",
      "\u001b[1;31mRateLimitExceededException\u001b[0m: 403 {\"documentation_url\": \"https://docs.github.com/en/free-pro-team@latest/rest/overview/resources-in-the-rest-api#secondary-rate-limits\", \"message\": \"You have exceeded a secondary rate limit. Please wait a few minutes before you try again.\"}"
     ]
    }
   ],
   "source": [
    "from github import Github\n",
    "import csv\n",
    "\n",
    "access_token = \"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\"\n",
    "\n",
    "# Authenticate using your access token\n",
    "g = Github(access_token)\n",
    "\n",
    "# Search repositories matching the criteria\n",
    "query = 'created:2023'  # Update the search query to match your desired criteria\n",
    "sort = 'stars'\n",
    "order = 'desc'\n",
    "\n",
    "repositories = g.search_repositories(query, sort, order)\n",
    "\n",
    "extracted_data = []\n",
    "\n",
    "for repo in repositories:\n",
    "    name = repo.name\n",
    "    url = repo.html_url\n",
    "    language = repo.language if repo.language else 'N/A'\n",
    "    stars = repo.stargazers_count\n",
    "    forks = repo.forks_count\n",
    "    extracted_data.append({'Name': name, 'URL': url, 'Language': language, 'Stars': stars, 'Forks': forks})\n",
    "\n",
    "# Define the CSV file path\n",
    "csv_file_path = 'repositories.csv'\n",
    "\n",
    "# Write the data to the CSV file\n",
    "with open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=['Name', 'URL', 'Language', 'Stars', 'Forks'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(extracted_data)\n",
    "\n",
    "print(f\"Data exported to {csv_file_path} successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afe82f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517c3fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "383a9352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'node', 'url': 'https://github.com/base-org/node', 'language': 'Shell', 'stars': 49608, 'forks': 1220}\n",
      "{'name': 'gpt4all', 'url': 'https://github.com/nomic-ai/gpt4all', 'language': 'C++', 'stars': 46337, 'forks': 4931}\n",
      "{'name': 'gpt4free', 'url': 'https://github.com/xtekky/gpt4free', 'language': 'Python', 'stars': 40198, 'forks': 10252}\n",
      "{'name': 'privateGPT', 'url': 'https://github.com/imartinez/privateGPT', 'language': 'Python', 'stars': 29991, 'forks': 3471}\n",
      "{'name': 'ChatGLM-6B', 'url': 'https://github.com/THUDM/ChatGLM-6B', 'language': 'Python', 'stars': 28587, 'forks': 3673}\n",
      "{'name': 'JARVIS', 'url': 'https://github.com/microsoft/JARVIS', 'language': 'Python', 'stars': 20980, 'forks': 1718}\n",
      "{'name': 'cursor', 'url': 'https://github.com/getcursor/cursor', 'language': 'N/A', 'stars': 15999, 'forks': 1227}\n",
      "{'name': 'babyagi', 'url': 'https://github.com/yoheinakajima/babyagi', 'language': 'Python', 'stars': 15363, 'forks': 2112}\n",
      "{'name': 'Chinese-LLaMA-Alpaca', 'url': 'https://github.com/ymcui/Chinese-LLaMA-Alpaca', 'language': 'Python', 'stars': 10930, 'forks': 1137}\n",
      "{'name': 'MOSS', 'url': 'https://github.com/OpenLMLab/MOSS', 'language': 'Python', 'stars': 10812, 'forks': 1050}\n",
      "{'name': 'chatGPTBox', 'url': 'https://github.com/josStorer/chatGPTBox', 'language': 'JavaScript', 'stars': 8123, 'forks': 560}\n",
      "{'name': 'dm-ticket', 'url': 'https://github.com/ClassmateLin/dm-ticket', 'language': 'Rust', 'stars': 5929, 'forks': 1322}\n",
      "{'name': 'bilingual_book_maker', 'url': 'https://github.com/yihong0618/bilingual_book_maker', 'language': 'Python', 'stars': 5845, 'forks': 858}\n",
      "{'name': 'LMFlow', 'url': 'https://github.com/OptimalScale/LMFlow', 'language': 'Python', 'stars': 5684, 'forks': 598}\n",
      "{'name': 'pygwalker', 'url': 'https://github.com/Kanaries/pygwalker', 'language': 'Python', 'stars': 5676, 'forks': 194}\n",
      "{'name': 'e2b', 'url': 'https://github.com/e2b-dev/e2b', 'language': 'Python', 'stars': 5111, 'forks': 445}\n",
      "{'name': 'bob-plugin-openai-translator', 'url': 'https://github.com/openai-translator/bob-plugin-openai-translator', 'language': 'JavaScript', 'stars': 4846, 'forks': 202}\n",
      "{'name': 'lit-llama', 'url': 'https://github.com/Lightning-AI/lit-llama', 'language': 'Python', 'stars': 4504, 'forks': 343}\n",
      "{'name': 'opencommit', 'url': 'https://github.com/di-sukharev/opencommit', 'language': 'JavaScript', 'stars': 4121, 'forks': 176}\n",
      "{'name': 'DragGAN', 'url': 'https://github.com/Zeqiang-Lai/DragGAN', 'language': 'Python', 'stars': 3963, 'forks': 398}\n",
      "{'name': 'openmoonray', 'url': 'https://github.com/dreamworksanimation/openmoonray', 'language': 'CMake', 'stars': 3793, 'forks': 228}\n",
      "{'name': 'node-chatgpt-api', 'url': 'https://github.com/waylaidwanderer/node-chatgpt-api', 'language': 'JavaScript', 'stars': 3707, 'forks': 652}\n",
      "{'name': 'clack', 'url': 'https://github.com/natemoo-re/clack', 'language': 'TypeScript', 'stars': 3646, 'forks': 53}\n",
      "{'name': 'turbopilot', 'url': 'https://github.com/ravenscroftj/turbopilot', 'language': 'Python', 'stars': 3530, 'forks': 116}\n",
      "{'name': 'Whisper', 'url': 'https://github.com/Const-me/Whisper', 'language': 'C++', 'stars': 3416, 'forks': 319}\n",
      "{'name': 'Voyager', 'url': 'https://github.com/MineDojo/Voyager', 'language': 'JavaScript', 'stars': 3306, 'forks': 277}\n",
      "{'name': 'Mindmap', 'url': 'https://github.com/Ignitetechnologies/Mindmap', 'language': 'N/A', 'stars': 3282, 'forks': 570}\n",
      "{'name': 'Huatuo-Llama-Med-Chinese', 'url': 'https://github.com/SCIR-HI/Huatuo-Llama-Med-Chinese', 'language': 'Python', 'stars': 3049, 'forks': 272}\n",
      "{'name': 'document.ai', 'url': 'https://github.com/GanymedeNil/document.ai', 'language': 'Python', 'stars': 3039, 'forks': 268}\n",
      "{'name': 'Text2Video-Zero', 'url': 'https://github.com/Picsart-AI-Research/Text2Video-Zero', 'language': 'Python', 'stars': 2893, 'forks': 204}\n",
      "{'name': 'ChatDoctor', 'url': 'https://github.com/Kent0n-Li/ChatDoctor', 'language': 'Python', 'stars': 2874, 'forks': 315}\n",
      "{'name': 'ChatGPT-Telegram-Workers', 'url': 'https://github.com/TBXark/ChatGPT-Telegram-Workers', 'language': 'JavaScript', 'stars': 2757, 'forks': 675}\n",
      "{'name': 'chatgpt-clone', 'url': 'https://github.com/xtekky/chatgpt-clone', 'language': 'Python', 'stars': 2752, 'forks': 852}\n",
      "{'name': 'open-source-alternatives', 'url': 'https://github.com/btw-so/open-source-alternatives', 'language': 'N/A', 'stars': 2628, 'forks': 113}\n",
      "{'name': 'faster-whisper', 'url': 'https://github.com/guillaumekln/faster-whisper', 'language': 'Python', 'stars': 2528, 'forks': 171}\n",
      "{'name': 'LLM-As-Chatbot', 'url': 'https://github.com/deep-diver/LLM-As-Chatbot', 'language': 'Python', 'stars': 2515, 'forks': 297}\n",
      "{'name': 'speechgpt', 'url': 'https://github.com/hahahumble/speechgpt', 'language': 'TypeScript', 'stars': 2514, 'forks': 377}\n",
      "{'name': 'heshijun_v_360', 'url': 'https://github.com/hax/heshijun_v_360', 'language': 'N/A', 'stars': 2495, 'forks': 166}\n",
      "{'name': 'unlocking-the-power-of-llms', 'url': 'https://github.com/howl-anderson/unlocking-the-power-of-llms', 'language': 'Shell', 'stars': 2362, 'forks': 152}\n",
      "{'name': 'pyllama', 'url': 'https://github.com/juncongmoo/pyllama', 'language': 'Python', 'stars': 2291, 'forks': 266}\n",
      "{'name': 'Auto-GPT-ZH', 'url': 'https://github.com/kaqijiang/Auto-GPT-ZH', 'language': 'Python', 'stars': 2121, 'forks': 366}\n",
      "{'name': 'openai-scf-proxy', 'url': 'https://github.com/Ice-Hazymoon/openai-scf-proxy', 'language': 'JavaScript', 'stars': 2111, 'forks': 300}\n",
      "{'name': 'homebrew-apple', 'url': 'https://github.com/apple/homebrew-apple', 'language': 'Ruby', 'stars': 2080, 'forks': 61}\n",
      "{'name': 'REALITY', 'url': 'https://github.com/XTLS/REALITY', 'language': 'Go', 'stars': 2016, 'forks': 133}\n",
      "{'name': 'chatgpt', 'url': 'https://github.com/dirk1983/chatgpt', 'language': 'JavaScript', 'stars': 2013, 'forks': 587}\n",
      "{'name': 'EditAnything', 'url': 'https://github.com/sail-sg/EditAnything', 'language': 'Python', 'stars': 1974, 'forks': 69}\n",
      "{'name': '3x-ui', 'url': 'https://github.com/MHSanaei/3x-ui', 'language': 'JavaScript', 'stars': 1863, 'forks': 330}\n",
      "{'name': 'codeium.vim', 'url': 'https://github.com/Exafunction/codeium.vim', 'language': 'Vim Script', 'stars': 1834, 'forks': 44}\n",
      "{'name': 'markprompt', 'url': 'https://github.com/motifland/markprompt', 'language': 'TypeScript', 'stars': 1832, 'forks': 136}\n",
      "{'name': 'tiny11builder', 'url': 'https://github.com/ntdevlabs/tiny11builder', 'language': 'Batchfile', 'stars': 1816, 'forks': 209}\n",
      "{'name': 'Free-Auto-GPT', 'url': 'https://github.com/IntelligenzaArtificiale/Free-Auto-GPT', 'language': 'Python', 'stars': 1810, 'forks': 243}\n",
      "{'name': 'VITS-fast-fine-tuning', 'url': 'https://github.com/Plachtaa/VITS-fast-fine-tuning', 'language': 'Python', 'stars': 1787, 'forks': 294}\n",
      "{'name': 'GPT_API_free', 'url': 'https://github.com/chatanywhere/GPT_API_free', 'language': 'Python', 'stars': 1771, 'forks': 188}\n",
      "{'name': 'floatui', 'url': 'https://github.com/MarsX-dev/floatui', 'language': 'JavaScript', 'stars': 1688, 'forks': 212}\n",
      "{'name': 'van', 'url': 'https://github.com/vanjs-org/van', 'language': 'JavaScript', 'stars': 1610, 'forks': 34}\n",
      "{'name': 'ChatGLM-webui', 'url': 'https://github.com/Akegarasu/ChatGLM-webui', 'language': 'Python', 'stars': 1579, 'forks': 226}\n",
      "{'name': 'kings-league-project', 'url': 'https://github.com/midudev/kings-league-project', 'language': 'JavaScript', 'stars': 1542, 'forks': 237}\n",
      "{'name': 'PhySO', 'url': 'https://github.com/WassimTenachi/PhySO', 'language': 'Python', 'stars': 1434, 'forks': 199}\n",
      "{'name': 'pix2pix3D', 'url': 'https://github.com/dunbar12138/pix2pix3D', 'language': 'Python', 'stars': 1428, 'forks': 106}\n",
      "{'name': 'NekoBoxForAndroid', 'url': 'https://github.com/MatsuriDayo/NekoBoxForAndroid', 'language': 'Kotlin', 'stars': 1389, 'forks': 83}\n",
      "{'name': 'chain-of-thought-hub', 'url': 'https://github.com/FranxYao/chain-of-thought-hub', 'language': 'Jupyter Notebook', 'stars': 1362, 'forks': 69}\n",
      "{'name': 'mirrorful', 'url': 'https://github.com/Mirrorful/mirrorful', 'language': 'TypeScript', 'stars': 1351, 'forks': 71}\n",
      "{'name': 'TigerBot', 'url': 'https://github.com/TigerResearch/TigerBot', 'language': 'Python', 'stars': 1348, 'forks': 134}\n",
      "{'name': 'cognitive-load', 'url': 'https://github.com/zakirullin/cognitive-load', 'language': 'N/A', 'stars': 1336, 'forks': 24}\n",
      "{'name': 'LangChain-ChatGLM-Webui', 'url': 'https://github.com/thomas-yanxin/LangChain-ChatGLM-Webui', 'language': 'Python', 'stars': 1327, 'forks': 171}\n",
      "{'name': 'Awesome-Anything', 'url': 'https://github.com/VainF/Awesome-Anything', 'language': 'N/A', 'stars': 1313, 'forks': 67}\n",
      "{'name': 'chatglm_finetuning', 'url': 'https://github.com/ssbuild/chatglm_finetuning', 'language': 'Python', 'stars': 1308, 'forks': 153}\n",
      "{'name': 'awesome-intelligence', 'url': 'https://github.com/ARPSyndicate/awesome-intelligence', 'language': 'N/A', 'stars': 1307, 'forks': 38}\n",
      "{'name': 'openpose-editor', 'url': 'https://github.com/fkunn1326/openpose-editor', 'language': 'Python', 'stars': 1278, 'forks': 146}\n",
      "{'name': 'ezno', 'url': 'https://github.com/kaleidawave/ezno', 'language': 'Rust', 'stars': 1275, 'forks': 20}\n",
      "{'name': 'StarRailAssistant', 'url': 'https://github.com/Starry-Wind/StarRailAssistant', 'language': 'Python', 'stars': 1234, 'forks': 162}\n",
      "{'name': 'GPTeacher', 'url': 'https://github.com/teknium1/GPTeacher', 'language': 'Python', 'stars': 1209, 'forks': 127}\n",
      "{'name': 'SparK', 'url': 'https://github.com/keyu-tian/SparK', 'language': 'Python', 'stars': 1205, 'forks': 55}\n",
      "{'name': 'RWKV-Runner', 'url': 'https://github.com/josStorer/RWKV-Runner', 'language': 'TypeScript', 'stars': 1184, 'forks': 83}\n",
      "{'name': 'DARC', 'url': 'https://github.com/Project-DARC/DARC', 'language': 'Solidity', 'stars': 1181, 'forks': 53}\n",
      "{'name': 'CodeTF', 'url': 'https://github.com/salesforce/CodeTF', 'language': 'Python', 'stars': 1161, 'forks': 66}\n",
      "{'name': 'Web3Bugs', 'url': 'https://github.com/ZhangZhuoSJTU/Web3Bugs', 'language': 'Solidity', 'stars': 1155, 'forks': 141}\n",
      "{'name': 'afet-org', 'url': 'https://github.com/acikkaynak/afet-org', 'language': 'HTML', 'stars': 1136, 'forks': 76}\n",
      "{'name': 'hyperDB', 'url': 'https://github.com/jdagdelen/hyperDB', 'language': 'Python', 'stars': 1098, 'forks': 44}\n",
      "{'name': 'FluentUI', 'url': 'https://github.com/zhuzichu520/FluentUI', 'language': 'QML', 'stars': 1080, 'forks': 124}\n",
      "{'name': 'cf-openai-azure-proxy', 'url': 'https://github.com/haibbo/cf-openai-azure-proxy', 'language': 'JavaScript', 'stars': 997, 'forks': 110}\n",
      "{'name': 'swissgl', 'url': 'https://github.com/google/swissgl', 'language': 'JavaScript', 'stars': 977, 'forks': 26}\n",
      "{'name': 'stylegan-t', 'url': 'https://github.com/autonomousvision/stylegan-t', 'language': 'Python', 'stars': 964, 'forks': 38}\n",
      "{'name': 'AutoPR', 'url': 'https://github.com/irgolic/AutoPR', 'language': 'Python', 'stars': 958, 'forks': 56}\n",
      "{'name': 'ZyPlayer', 'url': 'https://github.com/Hiram-Wong/ZyPlayer', 'language': 'Vue', 'stars': 934, 'forks': 142}\n",
      "{'name': 'chatgpt-google-summary-extension', 'url': 'https://github.com/sparticleinc/chatgpt-google-summary-extension', 'language': 'TypeScript', 'stars': 930, 'forks': 111}\n",
      "{'name': 'vite-plugin-vue-devtools', 'url': 'https://github.com/webfansplz/vite-plugin-vue-devtools', 'language': 'Vue', 'stars': 927, 'forks': 29}\n",
      "{'name': 'sveltekit-superforms', 'url': 'https://github.com/ciscoheat/sveltekit-superforms', 'language': 'TypeScript', 'stars': 916, 'forks': 17}\n",
      "{'name': 'StableDiffusionReconstruction', 'url': 'https://github.com/yu-takagi/StableDiffusionReconstruction', 'language': 'N/A', 'stars': 902, 'forks': 27}\n",
      "{'name': 'Chat-with-Github-Repo', 'url': 'https://github.com/peterw/Chat-with-Github-Repo', 'language': 'Python', 'stars': 885, 'forks': 115}\n",
      "{'name': 'ChatChat', 'url': 'https://github.com/okisdev/ChatChat', 'language': 'TypeScript', 'stars': 884, 'forks': 164}\n",
      "{'name': 'pybroker', 'url': 'https://github.com/edtechre/pybroker', 'language': 'Python', 'stars': 868, 'forks': 97}\n",
      "{'name': 'kubernetes-chatgpt-bot', 'url': 'https://github.com/robusta-dev/kubernetes-chatgpt-bot', 'language': 'Python', 'stars': 866, 'forks': 87}\n",
      "{'name': 'Alpaca-Turbo', 'url': 'https://github.com/ViperX7/Alpaca-Turbo', 'language': 'Python', 'stars': 861, 'forks': 90}\n",
      "{'name': 'AI-Functions', 'url': 'https://github.com/Torantulino/AI-Functions', 'language': 'Python', 'stars': 857, 'forks': 103}\n",
      "{'name': 'chatgpt-pgvector', 'url': 'https://github.com/gannonh/chatgpt-pgvector', 'language': 'TypeScript', 'stars': 848, 'forks': 119}\n",
      "{'name': 'tuning_playbook_zh_cn', 'url': 'https://github.com/schrodingercatss/tuning_playbook_zh_cn', 'language': 'N/A', 'stars': 846, 'forks': 79}\n",
      "{'name': 'editable-website', 'url': 'https://github.com/michael/editable-website', 'language': 'Svelte', 'stars': 839, 'forks': 52}\n",
      "{'name': 'Home-Assistant-Mobile-First', 'url': 'https://github.com/Clooos/Home-Assistant-Mobile-First', 'language': 'N/A', 'stars': 823, 'forks': 51}\n",
      "{'name': 'EVAL', 'url': 'https://github.com/corca-ai/EVAL', 'language': 'Python', 'stars': 780, 'forks': 72}\n",
      "Data exported to repositories.csv successfully.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "\n",
    "per_page = 100  # Number of repositories to retrieve per page\n",
    "page = 1  # Initial page number\n",
    "total_results = 0 \n",
    "\n",
    "# Send a GET request to the GitHub API to retrieve the trending repositories\n",
    "response = requests.get('https://api.github.com/search/repositories',\n",
    "                        params={'q': 'created:2023',\n",
    "        'sort': 'stars',\n",
    "        'order': 'desc',\n",
    "        'per_page': per_page,\n",
    "        'page': page})\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Get the JSON data from the response\n",
    "    data = response.json()\n",
    "\n",
    "    # Extract information from each repository\n",
    "    repositories = data['items']\n",
    "    extracted_data = []\n",
    "    for repo in repositories:\n",
    "        name = repo['name']\n",
    "        url = repo['html_url']\n",
    "        language = repo['language'] if repo['language'] else 'N/A'\n",
    "        stars = repo['stargazers_count']\n",
    "        forks = repo['forks_count']\n",
    "        extracted_data.append({'name': name, 'url': url, 'language': language, 'stars': stars, 'forks': forks})\n",
    "\n",
    "    # Print the extracted data\n",
    "    for item in extracted_data:\n",
    "        print(item)\n",
    "\n",
    "    # Define the CSV file path\n",
    "    csv_file_path = 'repositories.csv'\n",
    "\n",
    "    # Write the data to the CSV file\n",
    "    with open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow(['Name', 'URL', 'Language', 'Stars', 'Forks'])  # Write the header row\n",
    "        for item in extracted_data:\n",
    "            writer.writerow([item['name'], item['url'], item['language'], item['stars'], item['forks']])\n",
    "\n",
    "    print(f\"Data exported to {csv_file_path} successfully.\")\n",
    "\n",
    "else:\n",
    "    print(f\"Failed to retrieve data from the GitHub API. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35be326c",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 8 column 1 (char 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32m~\\miniconda3\\envs\\data_dev\\Lib\\site-packages\\requests\\models.py:971\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    973\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\data_dev\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_decoder\u001b[38;5;241m.\u001b[39mdecode(s)\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\data_dev\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_decode(s, idx\u001b[38;5;241m=\u001b[39m_w(s, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mend())\n\u001b[0;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\data_dev\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 8 column 1 (char 7)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Check if the response was successful\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m contributors_response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m---> 26\u001b[0m     contributors_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(contributors_response\u001b[38;5;241m.\u001b[39mjson())\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to retrieve contributors for repository: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\data_dev\\Lib\\site-packages\\requests\\models.py:975\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    973\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[1;32m--> 975\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 8 column 1 (char 7)"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "\n",
    "# Send a GET request to the GitHub API to retrieve the trending repositories\n",
    "response = requests.get('https://api.github.com/search/repositories',\n",
    "                        params={'q': 'stars:>5000', 'sort': 'stars', 'order': 'desc'})\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Get the JSON data from the response\n",
    "    data = response.json()\n",
    "\n",
    "    # Extract information from each repository\n",
    "    repositories = data['items']\n",
    "    extracted_data = []\n",
    "    for repo in repositories:\n",
    "        name = repo['name']\n",
    "        url = repo['html_url']\n",
    "\n",
    "        # Get contributors count\n",
    "        contributors_url = f\"{url}/contributors\"\n",
    "        contributors_response = requests.get(contributors_url)\n",
    "\n",
    "        # Check if the response was successful\n",
    "        if contributors_response.status_code == 200:\n",
    "            contributors_count = len(contributors_response.json())\n",
    "        else:\n",
    "            print(f\"Failed to retrieve contributors for repository: {name}\")\n",
    "            print(f\"Error message: {contributors_response.content}\")\n",
    "            continue\n",
    "\n",
    "        # Get issues count\n",
    "        issues_url = f\"{url}/issues\"\n",
    "        issues_response = requests.get(issues_url)\n",
    "\n",
    "        # Check if the response was successful\n",
    "        if issues_response.status_code == 200:\n",
    "            issues_count = len(issues_response.json())\n",
    "        else:\n",
    "            print(f\"Failed to retrieve issues for repository: {name}\")\n",
    "            print(f\"Error message: {issues_response.content}\")\n",
    "            continue\n",
    "\n",
    "        # Get forks count\n",
    "        forks_count = repo['forks_count']\n",
    "\n",
    "        # Get languages\n",
    "        languages_url = f\"{url}/languages\"\n",
    "        languages_response = requests.get(languages_url)\n",
    "\n",
    "        # Check if the response was successful\n",
    "        if languages_response.status_code == 200:\n",
    "            languages_data = languages_response.json()\n",
    "            languages = list(languages_data.keys())\n",
    "        else:\n",
    "            print(f\"Failed to retrieve languages for repository: {name}\")\n",
    "            print(f\"Error message: {languages_response.content}\")\n",
    "            continue\n",
    "\n",
    "        # Get stars count\n",
    "        stars = repo['stargazers_count']\n",
    "\n",
    "        extracted_data.append({'name': name, 'url': url, 'contributors': contributors_count,\n",
    "                               'issues_count': issues_count, 'forks_count': forks_count,\n",
    "                               'languages': languages, 'stars': stars})\n",
    "\n",
    "    # Print the extracted data\n",
    "    for item in extracted_data:\n",
    "        print(item)\n",
    "\n",
    "    # Define the CSV file path\n",
    "    csv_file_path = 'repositories.csv'\n",
    "\n",
    "    # Write the data to the CSV file\n",
    "    with open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow(['Name', 'URL', 'Contributors', 'Issues Count', 'Forks Count', 'Languages', 'Stars'])\n",
    "        for item in extracted_data:\n",
    "            writer.writerow([item['name'], item['url'], item['contributors'],\n",
    "                             item['issues_count'], item['forks_count'], ', '.join(item['languages']),\n",
    "                             item['stars']])\n",
    "\n",
    "    print(f\"Data exported to {csv_file_path} successfully.\")\n",
    "\n",
    "else:\n",
    "    print(f\"Failed to retrieve data from the GitHub API. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c4d6bf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching contributors for repository linux: 403 {\"message\": \"The history or contributor list is too large to list contributors for this repository via the API.\", \"documentation_url\": \"https://docs.github.com/rest/reference/repos#list-repository-contributors\"}\n",
      "{'name': 'freeCodeCamp', 'url': 'https://github.com/freeCodeCamp/freeCodeCamp', 'contributors': ['raisedadead', 'sahat', 'camperbot', 'renovate-bot', 'renovate[bot]', 'ojeytonwilliams', 'Bouncey', 'terakilobyte', 'SaintPeter', 'ltegman'], 'issues_count': 223, 'forks_count': 32408, 'languages': ['TypeScript', 'JavaScript', 'CSS', 'Dockerfile', 'EJS', 'HTML', 'Shell', 'Less'], 'stars': 368593}\n",
      "{'name': 'free-programming-books', 'url': 'https://github.com/EbookFoundation/free-programming-books', 'contributors': ['vhf', 'MHM5000', 'davorpa', 'alexanderfefelov', 'MrS4w', 'esparta', 'eshellman', 'kadhirash', 'borgified', 'ericguirbal'], 'issues_count': 49, 'forks_count': 55689, 'languages': [], 'stars': 283400}\n",
      "{'name': '996.ICU', 'url': 'https://github.com/996icu/996.ICU', 'contributors': ['996icu', 'ChangedenCZD', 'Z-fly', 'bofeiw', 'xianfengting', 'CPdogson', 'githubmll', 'Tedko', 'uDp30Z4w', 'zombie110year'], 'issues_count': 16733, 'forks_count': 21400, 'languages': [], 'stars': 266060}\n",
      "{'name': 'coding-interview-university', 'url': 'https://github.com/jwasham/coding-interview-university', 'contributors': ['jwasham', 'Anri-Lombard', 'avizmarlon', 'esaucedof', 'aleen42', 'Ilyushin', 'dossorio', 'hexatester', 'letientai299', 'DimoDimchev'], 'issues_count': 57, 'forks_count': 68092, 'languages': [], 'stars': 259559}\n",
      "{'name': 'awesome', 'url': 'https://github.com/sindresorhus/awesome', 'contributors': ['sindresorhus', 'davisonio', 'RichardLitt', 'arthurvr', 'kdeldycke', 'AllThingsSmitty', 'PatrickJS', 'johnjago', 'RayBB', 'stevestock'], 'issues_count': 69, 'forks_count': 25899, 'languages': [], 'stars': 257773}\n",
      "{'name': 'public-apis', 'url': 'https://github.com/public-apis/public-apis', 'contributors': ['matheusfelipeog', 'davemachado', 'pawelborkar', 'jbrooksuk', 'marekdano', 'mikestreety', 'toddmotto', 'yannbertrand', 'wesbos', 'olekstomek'], 'issues_count': 185, 'forks_count': 27797, 'languages': ['Python', 'Shell'], 'stars': 243785}\n",
      "{'name': 'developer-roadmap', 'url': 'https://github.com/kamranahmedse/developer-roadmap', 'contributors': ['kamranahmedse', 'iArchitSharma', 'paulmarsicloud', 'lovemycodesnippets', 'aroyan', 'andran777', 'adnn-alc', 'h-s04', 'CodeWithUma', 'syedmouaazfarrukh'], 'issues_count': 470, 'forks_count': 34070, 'languages': ['TypeScript', 'Astro', 'JavaScript', 'CSS'], 'stars': 241857}\n",
      "{'name': 'system-design-primer', 'url': 'https://github.com/donnemartin/system-design-primer', 'contributors': ['donnemartin', 'satob', 'fluency03', 'linhe0x0', 'antongulikov', 'fabriziocucci', 'ianpark', 'luisbg', 'manaskarekar', 'yangshun'], 'issues_count': 380, 'forks_count': 39344, 'languages': ['Python', 'Shell'], 'stars': 222143}\n",
      "{'name': 'react', 'url': 'https://github.com/facebook/react', 'contributors': ['zpao', 'gaearon', 'acdlite', 'sophiebits', 'sebmarkbage', 'jimfb', 'trueadm', 'bvaughn', 'petehunt', 'chenglou'], 'issues_count': 1304, 'forks_count': 43661, 'languages': ['JavaScript', 'HTML', 'CSS', 'C++', 'TypeScript', 'CoffeeScript', 'C', 'Shell', 'Python', 'Makefile'], 'stars': 208971}\n",
      "{'name': 'build-your-own-x', 'url': 'https://github.com/codecrafters-io/build-your-own-x', 'contributors': ['danistefanovic', 'rohitpaulk', 'fake-rookie', 'sarupbanskota', 'bauripalash', 'louisnguyencreative', 'danielbarnes175', 'jserv', 'imlakshay08', 'mstuttgart'], 'issues_count': 278, 'forks_count': 19887, 'languages': [], 'stars': 204218}\n",
      "{'name': 'vue', 'url': 'https://github.com/vuejs/vue', 'contributors': ['yyx990803', 'vue-bot', 'Hanks10100', 'posva', 'defcc', 'kazupon', 'pikax', 'ktsn', 'HerringtonDarkholme', 'javoski'], 'issues_count': 638, 'forks_count': 33878, 'languages': ['TypeScript', 'JavaScript', 'HTML', 'CSS', 'Shell'], 'stars': 204069}\n",
      "{'name': 'tensorflow', 'url': 'https://github.com/tensorflow/tensorflow', 'contributors': ['tensorflower-gardener', 'mihaimaruseac', 'yongtang', 'gunan', 'caisq', 'hawkinsp', 'mrry', 'roserg', 'akuegel', 'benoitsteiner'], 'issues_count': 2130, 'forks_count': 88451, 'languages': ['C++', 'Python', 'MLIR', 'Starlark', 'HTML', 'Go', 'C', 'Java', 'Jupyter Notebook', 'Shell', 'Objective-C++', 'CMake', 'Objective-C', 'Smarty', 'Swift', 'Batchfile', 'SourcePawn', 'C#', 'Ruby', 'Perl', 'LLVM', 'Pawn', 'Dockerfile', 'Cython', 'Roff', 'Makefile', 'Vim Snippet'], 'stars': 175518}\n",
      "{'name': 'javascript-algorithms', 'url': 'https://github.com/trekhleb/javascript-algorithms', 'contributors': ['trekhleb', 'm-maksyutin', 'appleJax', 'albertstill', 'moshejs', 'fveronezipeters', 'jpvg10', 'niltonslf', 'alexanderkhivrych', 'RequireSun'], 'issues_count': 311, 'forks_count': 28083, 'languages': ['JavaScript', 'Shell'], 'stars': 171265}\n",
      "{'name': 'awesome-python', 'url': 'https://github.com/vinta/awesome-python', 'contributors': ['vinta', 'dhamaniasad', 'ellisonleao', 'ihebu', 'Alir3z4', 'nicoe', 'agroszer', 'makrusak', 'quobit', 'fkromer'], 'issues_count': 356, 'forks_count': 23307, 'languages': ['Python', 'Makefile'], 'stars': 171000}\n",
      "{'name': 'You-Dont-Know-JS', 'url': 'https://github.com/getify/You-Dont-Know-JS', 'contributors': ['getify', 'machineloop', 'pdawyndt', '4thana', 'zackgao', 'harpreetkhalsagtbit', 'magul', 'ryanplusplus', 'diogocampos', 'imurchie'], 'issues_count': 131, 'forks_count': 32661, 'languages': [], 'stars': 168867}\n",
      "{'name': 'CS-Notes', 'url': 'https://github.com/CyC2018/CS-Notes', 'contributors': ['CyC2018', 'kwongtailau', 'linehk', 'crossoverJie', '0xkookoo', 'Silverados', 'MachineChen', 'xiangmingzhe0928', 'xiangflight', 'somone23412'], 'issues_count': 183, 'forks_count': 50250, 'languages': [], 'stars': 164895}\n",
      "{'name': 'bootstrap', 'url': 'https://github.com/twbs/bootstrap', 'contributors': ['mdo', 'cvrebert', 'XhmikosR', 'fat', 'dependabot[bot]', 'patrickhlauke', 'Johann-S', 'MartijnCuppens', 'GeoSot', 'hnrch02'], 'issues_count': 400, 'forks_count': 78558, 'languages': ['JavaScript', 'HTML', 'SCSS', 'CSS', 'PowerShell'], 'stars': 164201}\n",
      "{'name': 'Python', 'url': 'https://github.com/TheAlgorithms/Python', 'contributors': ['harshildarji', 'cclauss', 'dhruvmanila', 'dynamitechetan', 'MaximSmolskiy', 'AnupKumarPanwar', 'duyuanch', 'SandersLin', 'christianbender', 'CaedenPH'], 'issues_count': 171, 'forks_count': 40307, 'languages': ['Python'], 'stars': 159831}\n",
      "{'name': 'ohmyzsh', 'url': 'https://github.com/ohmyzsh/ohmyzsh', 'contributors': ['robbyrussell', 'mcornella', 'apjanke', 'carlosala', 'fred-o', 'ncanceill', 'To1ne', 'LFDM', 'felipec', 'dimensi0n'], 'issues_count': 619, 'forks_count': 25306, 'languages': ['Shell', 'Python', 'Makefile'], 'stars': 159822}\n",
      "{'name': 'flutter', 'url': 'https://github.com/flutter/flutter', 'contributors': ['engine-flutter-autoroll', 'abarth', 'jonahwilliams', 'Hixie', 'jmagman', 'goderbauer', 'devoncarew', 'gspencergoog', 'cbracken', 'jason-simmons'], 'issues_count': 11546, 'forks_count': 25482, 'languages': ['Dart', 'C++', 'Objective-C', 'Java', 'CMake', 'Groovy', 'Shell', 'Ruby', 'HTML', 'JavaScript', 'Swift', 'Batchfile', 'Kotlin', 'C', 'CSS', 'Dockerfile', 'PowerShell', 'GLSL'], 'stars': 154291}\n",
      "{'name': 'linux', 'url': 'https://github.com/torvalds/linux', 'contributors': [], 'issues_count': 312, 'forks_count': 48460, 'languages': ['C', 'Assembly', 'Shell', 'Makefile', 'Python', 'Perl', 'Rust', 'C++', 'Roff', 'SmPL', 'Yacc', 'Lex', 'Awk', 'UnrealScript', 'Gherkin', 'Raku', 'M4', 'MATLAB', 'Clojure', 'XS', 'sed'], 'stars': 153152}\n",
      "{'name': 'gitignore', 'url': 'https://github.com/github/gitignore', 'contributors': ['shiftkey', 'arcresu', 'aroben', 'bdougie', 'defunkt', 'jspahrsummers', 'martinwoodward', 'thedaniel', 'd2s', 'haacked'], 'issues_count': 418, 'forks_count': 84161, 'languages': [], 'stars': 148876}\n",
      "{'name': 'vscode', 'url': 'https://github.com/microsoft/vscode', 'contributors': ['bpasero', 'jrieken', 'joaomoreno', 'mjbvz', 'Tyriar', 'alexdima', 'sandy081', 'isidorn', 'aeschli', 'rebornix'], 'issues_count': 7134, 'forks_count': 25914, 'languages': ['TypeScript', 'JavaScript', 'CSS', 'Rust', 'HTML', 'Inno Setup', 'Shell', 'Scilab', 'Batchfile', 'PowerShell', 'SCSS', 'Groovy', 'Cuda', 'C++', 'Makefile', 'Python', 'Perl', 'Ruby', 'TeX', 'Objective-C', 'Objective-C++', 'Clojure', 'Handlebars', 'Less', 'PHP', 'Julia', 'Jupyter Notebook', 'Visual Basic .NET', 'Dockerfile', 'C', 'C#', 'Pug', 'Go', 'F#', 'Java', 'CoffeeScript', 'R', 'Roff', 'ShaderLab', 'Dart', 'Swift', 'Lua', 'HLSL', 'Hack'], 'stars': 147253}\n",
      "{'name': 'computer-science', 'url': 'https://github.com/ossu/computer-science', 'contributors': ['ericdouglas', 'waciumawanjohi', 'joshmhanson', 'mkghosh', 'spamegg1', 'aayushsinha0706', 'Alaharon123', 'aaronhooper', 'jimages', 'Peillach'], 'issues_count': 15, 'forks_count': 18086, 'languages': [], 'stars': 140662}\n",
      "{'name': 'Auto-GPT', 'url': 'https://github.com/Significant-Gravitas/Auto-GPT', 'contributors': ['Torantulino', 'richbeales', 'BillSchumacher', 'merwanehamadi', 'Pwuts', 'AndresCdo', 'p-i-', 'cryptidv', 'ntindle', 'maiko'], 'issues_count': 737, 'forks_count': 29482, 'languages': ['Python', 'Dockerfile', 'Shell', 'JavaScript', 'Batchfile'], 'stars': 139518}\n",
      "{'name': 'the-art-of-command-line', 'url': 'https://github.com/jlevy/the-art-of-command-line', 'contributors': ['jlevy', 'petk', 'Psycho7', 'stepan0904', 'ericguirbal', 'olegberman', 'niltonvasques', 'anna-d', 'Ungsik-Yun', 'dspinellis'], 'issues_count': 223, 'forks_count': 13615, 'languages': [], 'stars': 136923}\n",
      "{'name': 'Python-100-Days', 'url': 'https://github.com/jackfrued/Python-100-Days', 'contributors': ['jackfrued', 'softpo', 'geekya215', 'JalanJiang', 'jankeromnes', 'LingrenKong', 'nasyxx', 'TinaryTree', 'leemamas', 'royaso'], 'issues_count': 681, 'forks_count': 49256, 'languages': ['Python', 'HTML', 'Jupyter Notebook', 'Java', 'CSS', 'JavaScript'], 'stars': 136726}\n",
      "{'name': 'awesome-selfhosted', 'url': 'https://github.com/awesome-selfhosted/awesome-selfhosted', 'contributors': ['nodiscc', 'KieranRobson', 'n8225', 'Kickball', 'fabacab', 'mzch', 'Kovah', 'worldworm', 'cavebeat', 'kokomo123'], 'issues_count': 85, 'forks_count': 7762, 'languages': ['Makefile'], 'stars': 135920}\n",
      "{'name': 'javascript', 'url': 'https://github.com/airbnb/javascript', 'contributors': ['ljharb', 'hshoff', 'lencioni', 'goatslacker', 'justjake', 'sharmilajesupaul', '1pete', 'vsemozhetbyt', 'ssorallen', 'chrisngobanh'], 'issues_count': 158, 'forks_count': 25688, 'languages': ['JavaScript'], 'stars': 134922}\n",
      "{'name': 'JavaGuide', 'url': 'https://github.com/Snailclimb/JavaGuide', 'contributors': ['Snailclimb', 'samho2008', 'TommyMerlin', 'Mister-Hope', 'LiWenGu', 'haiqiang0225', 'Xunzhuo', 'Ryze-Zhao', 'ipofss', 'fanofxiaofeng'], 'issues_count': 64, 'forks_count': 44177, 'languages': ['Java', 'Shell'], 'stars': 134479}\n",
      "{'name': 'youtube-dl', 'url': 'https://github.com/ytdl-org/youtube-dl', 'contributors': ['dstftw', 'phihag', 'remitamine', 'jaimeMF', 'rg3', 'FiloSottile', 'dirkf', 'pulpe', 'Tithen-Firion', 'gcmalloc'], 'issues_count': 4730, 'forks_count': 9048, 'languages': ['Python', 'Shell', 'Makefile', 'ActionScript', 'Batchfile'], 'stars': 121065}\n",
      "{'name': 'fucking-algorithm', 'url': 'https://github.com/labuladong/fucking-algorithm', 'contributors': ['labuladong', 'brucecat', 'JodyZ0203', 'Jasper-Joe', 'kkty39', 'csguojin', 'eric496', 'tianzhongwei', 'ChenjieXu', 'MarineJoker'], 'issues_count': 321, 'forks_count': 22392, 'languages': ['Markdown'], 'stars': 116497}\n",
      "{'name': '30-seconds-of-code', 'url': 'https://github.com/30-seconds/30-seconds-of-code', 'contributors': ['Chalarangelo', 'kriadmin', '30secondsofcode', 'Trinityyi', 'fejes713', 'atomiks', 'kingdavidmartins', 'skatcat31', 'arjunmahishi', 'iamsoorena'], 'issues_count': 1, 'forks_count': 11614, 'languages': ['JavaScript'], 'stars': 113149}\n",
      "{'name': 'go', 'url': 'https://github.com/golang/go', 'contributors': ['rsc', 'griesemer', 'robpike', 'ianlancetaylor', 'bradfitz', 'aclements', 'mdempsky', 'josharian', 'randall77', 'cherrymui'], 'issues_count': 8372, 'forks_count': 16664, 'languages': ['Go', 'Assembly', 'HTML', 'C', 'Shell', 'Perl', 'JavaScript', 'Python', 'Batchfile', 'Dockerfile', 'Awk', 'Makefile'], 'stars': 112135}\n",
      "{'name': 'react-native', 'url': 'https://github.com/facebook/react-native', 'contributors': ['shergin', 'mdvacca', 'sammy-SC', 'RSNara', 'JoshuaGross', 'javache', 'hramos', 'davidaurelio', 'cortinico', 'sahrens'], 'issues_count': 1946, 'forks_count': 23375, 'languages': ['Java', 'C++', 'JavaScript', 'Objective-C', 'Objective-C++', 'Kotlin', 'Ruby', 'Shell', 'TypeScript', 'CMake', 'C', 'Assembly', 'HTML', 'Batchfile'], 'stars': 110077}\n",
      "{'name': 'electron', 'url': 'https://github.com/electron/electron', 'contributors': ['zcbenz', 'kevinsawicki', 'codebytere', 'MarshallOfSound', 'nornagon', 'deepak1556', 'electron-bot', 'miniak', 'zeke', 'sudowoodo-release-bot[bot]'], 'issues_count': 914, 'forks_count': 14726, 'languages': ['C++', 'TypeScript', 'Objective-C++', 'JavaScript', 'Python', 'Objective-C', 'HTML', 'Shell', 'Batchfile', 'C', 'CSS', 'PowerShell'], 'stars': 107754}\n",
      "{'name': 'next.js', 'url': 'https://github.com/vercel/next.js', 'contributors': ['ijjk', 'timneutkens', 'Timer', 'huozhi', 'shuding', 'sokra', 'arunoda', 'styfle', 'nkzawa', 'balazsorban44'], 'issues_count': 2110, 'forks_count': 24089, 'languages': ['JavaScript', 'TypeScript', 'Rust', 'CSS', 'SCSS', 'Shell', 'Dockerfile', 'Batchfile', 'Sass'], 'stars': 107696}\n",
      "{'name': 'project-based-learning', 'url': 'https://github.com/practical-tutorials/project-based-learning', 'contributors': ['tuvtran', 'sayands', 'enkeyz', 'bobeff', 'olucode', 'adilkhash', 'biodunch', 'jodylecompte', 'MacAhmed', 'itsmingjie'], 'issues_count': 39, 'forks_count': 14866, 'languages': [], 'stars': 106616}\n",
      "{'name': 'd3', 'url': 'https://github.com/d3/d3', 'contributors': ['mbostock', 'jasondavies', 'Fil', 'kitmonisit', '27359794', 'larskotthoff', 'natevw', 'yasirs', 'square-build-bot', 'jheer'], 'issues_count': 3, 'forks_count': 23328, 'languages': ['Shell', 'JavaScript'], 'stars': 105627}\n",
      "{'name': 'transformers', 'url': 'https://github.com/huggingface/transformers', 'contributors': ['thomwolf', 'sgugger', 'LysandreJik', 'patrickvonplaten', 'ydshieh', 'stas00', 'julien-c', 'sshleifer', 'Narsil', 'patil-suraj'], 'issues_count': 768, 'forks_count': 20944, 'languages': ['Python', 'Cuda', 'Shell', 'Dockerfile', 'C++', 'C', 'Makefile', 'Cython', 'Jsonnet'], 'stars': 103900}\n",
      "{'name': 'awesome-go', 'url': 'https://github.com/avelino/awesome-go', 'contributors': ['mholt', 'avelino', 'kirillDanshin', 'dmitshur', 'matrixik', 'kazhuravlev', 'cassiobotaro', 'hoffoo', 'spekary', 'dukex'], 'issues_count': 144, 'forks_count': 11014, 'languages': ['Go'], 'stars': 103181}\n",
      "{'name': 'free-programming-books-zh_CN', 'url': 'https://github.com/justjavac/free-programming-books-zh_CN', 'contributors': ['justjavac', 'spacewander', 'hacpai', 'hoosin', 'wizardforcel', 'FYLSen', 'qha0731', 'SDLyu', 'wangminli', 'myd7349'], 'issues_count': 28, 'forks_count': 27571, 'languages': [], 'stars': 102916}\n",
      "{'name': 'axios', 'url': 'https://github.com/axios/axios', 'contributors': ['mzabriskie', 'nickuraltsev', 'jasonsaayman', 'DigitalBrainJS', 'emilyemorehouse', 'dependabot[bot]', 'rubennorte', 'JustinBeckwith', 'codeclown', 'chinesedfan'], 'issues_count': 451, 'forks_count': 10369, 'languages': ['JavaScript', 'TypeScript', 'HTML', 'Handlebars'], 'stars': 100575}\n",
      "{'name': 'create-react-app', 'url': 'https://github.com/facebook/create-react-app', 'contributors': ['gaearon', 'Timer', 'iansu', 'ianschmitz', 'selbekk', 'fson', 'mrmckeb', 'vjeux', 'viankakrisna', 'matrush'], 'issues_count': 2038, 'forks_count': 26413, 'languages': ['JavaScript', 'Shell', 'CSS', 'HTML', 'AppleScript', 'TypeScript', 'SCSS', 'Sass'], 'stars': 100073}\n",
      "{'name': 'the-book-of-secret-knowledge', 'url': 'https://github.com/trimstray/the-book-of-secret-knowledge', 'contributors': ['trimstray', 'lbonanomi', 'loweryaustin', 'the4rchangel', 'ocamlx', 'crypt0rr', 'rammanokar', 'fabidick22', 'trevorbryant', 'alex3305'], 'issues_count': 44, 'forks_count': 7369, 'languages': [], 'stars': 100027}\n",
      "Data exported to repositories.csv successfully.\n"
     ]
    }
   ],
   "source": [
    "from github import Github\n",
    "import csv\n",
    "\n",
    "access_token = \"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\"\n",
    "\n",
    "# Create a GitHub instance and authenticate\n",
    "g = Github(access_token)\n",
    "\n",
    "# Search for trending repositories\n",
    "trending_repos = g.search_repositories(query='stars:>100000', sort='stars', order='desc')\n",
    "\n",
    "# Extract information from each repository\n",
    "extracted_data = []\n",
    "for repo in trending_repos:\n",
    "    name = repo.name\n",
    "    url = repo.html_url\n",
    "\n",
    "    try:\n",
    "        # Fetch contributors and limit to top 10\n",
    "        contributors = [contributor.login for contributor in repo.get_contributors()[:10]]\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching contributors for repository {name}: {str(e)}\")\n",
    "        contributors = []\n",
    "\n",
    "    issues_count = repo.open_issues_count\n",
    "    forks_count = repo.forks_count\n",
    "    languages = list(repo.get_languages().keys())\n",
    "    stars = repo.stargazers_count\n",
    "\n",
    "    extracted_data.append({'name': name, 'url': url, 'contributors': contributors,\n",
    "                           'issues_count': issues_count, 'forks_count': forks_count,\n",
    "                           'languages': languages, 'stars': stars})\n",
    "\n",
    "# Print the extracted data\n",
    "for item in extracted_data:\n",
    "    print(item)\n",
    "\n",
    "# Define the CSV file path\n",
    "csv_file_path = 'repositories.csv'\n",
    "\n",
    "# Write the data to the CSV file\n",
    "with open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(['Name', 'URL', 'Contributors', 'Issues Count', 'Forks Count', 'Languages', 'Stars'])\n",
    "    for item in extracted_data:\n",
    "        writer.writerow([item['name'], item['url'], ', '.join(item['contributors']),\n",
    "                         item['issues_count'], item['forks_count'], ', '.join(item['languages']),\n",
    "                         item['stars']])\n",
    "\n",
    "print(f\"Data exported to {csv_file_path} successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e995eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching contributors for repository sample-backyard-birds: list index out of range\n",
      "Error fetching contributors for repository oni-guide: list index out of range\n",
      "Error fetching contributors for repository inline-syscall: list index out of range\n",
      "Error fetching contributors for repository fic_sharepreferences_example: list index out of range\n",
      "Error fetching contributors for repository msdf_c: list index out of range\n",
      "Error fetching contributors for repository backend: list index out of range\n",
      "Error fetching contributors for repository itsy-gitsy: list index out of range\n",
      "Error fetching contributors for repository fic_flutter_bloc_example: list index out of range\n",
      "Error fetching contributors for repository backend: list index out of range\n",
      "Error fetching contributors for repository rarbg-db-dumps: list index out of range\n",
      "Error fetching contributors for repository hltv-stats: list index out of range\n",
      "Error fetching contributors for repository minilmv2.bb: list index out of range\n",
      "Error fetching contributors for repository bringup-bench: list index out of range\n",
      "Error fetching contributors for repository AppleWebiste3D: list index out of range\n",
      "Processed 1000 repositories. Waiting for 10 minutes...\n",
      "Data exported to repos2023.csv and repos2023.xlsx successfully.\n"
     ]
    }
   ],
   "source": [
    "from github import Github\n",
    "import csv\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "access_token = \"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\"\n",
    "\n",
    "# Create a GitHub instance and authenticate\n",
    "g = Github(access_token)\n",
    "\n",
    "# Retrieve repositories created during the year 2023\n",
    "repositories = g.search_repositories(query='created:2023')\n",
    "\n",
    "# Extract information from each repository\n",
    "extracted_data = []\n",
    "for i, repo in enumerate(repositories):\n",
    "    name = repo.name\n",
    "    url = repo.html_url\n",
    "\n",
    "    try:\n",
    "        contributors = [contributor.login for contributor in repo.get_contributors()[:5]]\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching contributors for repository {name}: {str(e)}\")\n",
    "        contributors = []\n",
    "\n",
    "    issues_count = repo.open_issues_count\n",
    "    forks_count = repo.forks_count\n",
    "    languages = list(repo.get_languages().keys())\n",
    "    stars = repo.stargazers_count\n",
    "\n",
    "    extracted_data.append({'Name': name, 'URL': url, 'Contributors': ', '.join(contributors),\n",
    "                           'Issues Count': issues_count, 'Forks Count': forks_count,\n",
    "                           'Languages': ', '.join(languages), 'Stars': stars})\n",
    "\n",
    "    # Pause after processing every 1000 repositories\n",
    "    if (i + 1) % 1000 == 0:\n",
    "        print(f\"Processed {i + 1} repositories. Waiting for 10 minutes...\")\n",
    "        time.sleep(600)  # Sleep for 10 minutes (600 seconds)\n",
    "\n",
    "while repositories._couldGrow():\n",
    "    repositories = repositories._grow()\n",
    "    for i, repo in enumerate(repositories):\n",
    "        name = repo.name\n",
    "        url = repo.html_url\n",
    "\n",
    "        try:\n",
    "            contributors = [contributor.login for contributor in repo.get_contributors()[:5]]\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching contributors for repository {name}: {str(e)}\")\n",
    "            contributors = []\n",
    "\n",
    "        issues_count = repo.open_issues_count\n",
    "        forks_count = repo.forks_count\n",
    "        languages = list(repo.get_languages().keys())\n",
    "        stars = repo.stargazers_count\n",
    "\n",
    "        extracted_data.append({'Name': name, 'URL': url, 'Contributors': ', '.join(contributors),\n",
    "                               'Issues Count': issues_count, 'Forks Count': forks_count,\n",
    "                               'Languages': ', '.join(languages), 'Stars': stars})\n",
    "\n",
    "        # Pause after processing every 1000 repositories\n",
    "        if (i + 1) % 1000 == 0:\n",
    "            print(f\"Processed {i + 1} repositories. Waiting for 10 minutes...\")\n",
    "            time.sleep(600)  # Sleep for 10 minutes (600 seconds)\n",
    "\n",
    "df = pd.DataFrame(extracted_data)\n",
    "\n",
    "csv_file_path = 'repos2023.csv'\n",
    "excel_file_path = 'repos2023.xlsx'\n",
    "\n",
    "df.to_csv(csv_file_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "# Write the data to the Excel file\n",
    "df.to_excel(excel_file_path, index=False)\n",
    "\n",
    "print(f\"Data exported to {csv_file_path} and {excel_file_path} successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bec8c028",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching contributors for repository RERQRQ: list index out of range\n",
      "Error fetching contributors for repository BibleBuddy: list index out of range\n",
      "Error fetching contributors for repository Assignment-1: list index out of range\n",
      "Error fetching contributors for repository Assignment-I: list index out of range\n",
      "Error fetching contributors for repository q: list index out of range\n",
      "Error fetching contributors for repository mdrazonho: list index out of range\n",
      "Error fetching contributors for repository BTK_2d_oyun_1: list index out of range\n",
      "Error fetching contributors for repository q: list index out of range\n",
      "Error fetching contributors for repository Chapter1: list index out of range\n",
      "Error fetching contributors for repository 1: list index out of range\n",
      "Error fetching contributors for repository vvr: list index out of range\n",
      "Error fetching contributors for repository q: list index out of range\n",
      "Error fetching contributors for repository q: list index out of range\n",
      "Error fetching contributors for repository q: list index out of range\n",
      "Error fetching contributors for repository meru: list index out of range\n",
      "Error fetching contributors for repository Quest-8: list index out of range\n",
      "Error fetching contributors for repository Top_HR_Interview_Question: list index out of range\n",
      "Error fetching contributors for repository Coloring-Book: list index out of range\n",
      "Error fetching contributors for repository q: list index out of range\n",
      "Error fetching contributors for repository project: list index out of range\n",
      "Error fetching contributors for repository qq: list index out of range\n",
      "Error fetching contributors for repository -: list index out of range\n",
      "Error fetching contributors for repository fictional-fiesta: list index out of range\n",
      "Error fetching contributors for repository lab06_javaqq: list index out of range\n",
      "Error fetching contributors for repository Documents: list index out of range\n",
      "Error fetching contributors for repository J: list index out of range\n",
      "Error fetching contributors for repository mygit: list index out of range\n",
      "Error fetching contributors for repository lab2: list index out of range\n",
      "Error fetching contributors for repository wds: list index out of range\n",
      "Error fetching contributors for repository Q: list index out of range\n",
      "Error fetching contributors for repository facqst: list index out of range\n",
      "Error fetching contributors for repository q: list index out of range\n",
      "Error fetching contributors for repository searchengine: list index out of range\n",
      "Error fetching contributors for repository Avalanche-Quest5: list index out of range\n",
      "Error fetching contributors for repository back4app: list index out of range\n",
      "Error fetching contributors for repository asdf: list index out of range\n",
      "Error fetching contributors for repository q: list index out of range\n",
      "Error fetching contributors for repository dsa: list index out of range\n",
      "Error fetching contributors for repository test: list index out of range\n",
      "Error fetching contributors for repository Ritika: list index out of range\n",
      "Error fetching contributors for repository q: list index out of range\n",
      "Error fetching contributors for repository s561sun: list index out of range\n",
      "Error fetching contributors for repository kjwef: list index out of range\n",
      "Error fetching contributors for repository q: list index out of range\n",
      "Error fetching contributors for repository qqq: list index out of range\n",
      "Error fetching contributors for repository Project_KD1: list index out of range\n",
      "Error fetching contributors for repository react_portifolio: list index out of range\n",
      "Error fetching contributors for repository gpt-pdf-qa: list index out of range\n",
      "Error fetching contributors for repository ET-Library: list index out of range\n",
      "Error fetching contributors for repository Ass: list index out of range\n",
      "Error fetching contributors for repository ORBEATER: list index out of range\n",
      "Error fetching contributors for repository angelo: list index out of range\n",
      "Error fetching contributors for repository Q-learning: list index out of range\n",
      "Error fetching contributors for repository Q: list index out of range\n",
      "Error fetching contributors for repository mt6785: 403 {\"message\": \"The history or contributor list is too large to list contributors for this repository via the API.\", \"documentation_url\": \"https://docs.github.com/rest/reference/repos#list-repository-contributors\"}\n",
      "Error fetching contributors for repository q-express: list index out of range\n",
      "Error fetching contributors for repository custom_stackoverflow_frontend: list index out of range\n",
      "Error fetching contributors for repository 123: list index out of range\n",
      "Error fetching contributors for repository khan-zada: list index out of range\n",
      "Error fetching contributors for repository 123: list index out of range\n",
      "Error fetching contributors for repository opperWeb: list index out of range\n",
      "Error fetching contributors for repository Basavanagudi: list index out of range\n",
      "Error fetching contributors for repository flutter: list index out of range\n",
      "Error fetching contributors for repository kaminaOOP: list index out of range\n",
      "Error fetching contributors for repository mudanomereact: list index out of range\n",
      "Error fetching contributors for repository AI: list index out of range\n",
      "Error fetching contributors for repository KBC_GAME: list index out of range\n",
      "Error fetching contributors for repository Jan26th2023: list index out of range\n",
      "Error fetching contributors for repository AQ: list index out of range\n",
      "Error fetching contributors for repository q-express-flutter-app: list index out of range\n",
      "Error fetching contributors for repository Reinforcement_project1: list index out of range\n",
      "Error fetching contributors for repository Que-Kitchen: list index out of range\n",
      "Error fetching contributors for repository qcore: list index out of range\n",
      "Error fetching contributors for repository redesigned-happiness: list index out of range\n",
      "Error fetching contributors for repository El-primero-: list index out of range\n",
      "Error fetching contributors for repository demoblaze_QA_test: list index out of range\n",
      "Error fetching contributors for repository prueba: list index out of range\n",
      "Error fetching contributors for repository qna: list index out of range\n",
      "Error fetching contributors for repository redesigned-happiness: list index out of range\n",
      "Error fetching contributors for repository chatbot-api: list index out of range\n",
      "Error fetching contributors for repository prueba: list index out of range\n",
      "Error fetching contributors for repository x-uc-suy: list index out of range\n",
      "Error fetching contributors for repository ShadowRocket: list index out of range\n",
      "Error fetching contributors for repository KUMAR: list index out of range\n",
      "Error fetching contributors for repository qa-express: list index out of range\n",
      "Error fetching contributors for repository maze-gen-q-learning: list index out of range\n",
      "Error fetching contributors for repository CREATIVE-COMMONS: list index out of range\n",
      "Error fetching contributors for repository BQC_Q48: list index out of range\n",
      "Error fetching contributors for repository Q_spiders_Assignments: list index out of range\n",
      "Error fetching contributors for repository Cagadas-da-vida: list index out of range\n",
      "Error fetching contributors for repository Q_spiders_Assignments: list index out of range\n",
      "Error fetching contributors for repository Cagadas-da-vida: list index out of range\n",
      "Error fetching contributors for repository yun-Screen: list index out of range\n",
      "Error fetching contributors for repository codigo-de-censura: list index out of range\n",
      "Error fetching contributors for repository Programacion_I: list index out of range\n",
      "Error fetching contributors for repository Anuel: list index out of range\n",
      "Error fetching contributors for repository preference-IQL: list index out of range\n",
      "Error fetching contributors for repository fullstack: list index out of range\n",
      "Error fetching contributors for repository my-question-in-StackOverflow: list index out of range\n",
      "Error fetching contributors for repository vue3-toeat: list index out of range\n",
      "Error fetching contributors for repository leetcode_hackerrank: list index out of range\n",
      "Error fetching contributors for repository CourseWork: list index out of range\n",
      "Error fetching contributors for repository risk_ai: list index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching contributors for repository 3: list index out of range\n",
      "Error fetching contributors for repository atividade-bebidas: list index out of range\n",
      "Error fetching contributors for repository 3: list index out of range\n",
      "Error fetching contributors for repository portfolio: list index out of range\n",
      "Error fetching contributors for repository ra: list index out of range\n",
      "Error fetching contributors for repository Ujian_Praktik_Reinforcement_Learning_Q-Learning: list index out of range\n",
      "Error fetching contributors for repository quickly-recognized: list index out of range\n",
      "Error fetching contributors for repository mytaxiapp: list index out of range\n",
      "Error fetching contributors for repository tha: list index out of range\n",
      "Error fetching contributors for repository TPN-1-de-zeb: list index out of range\n",
      "Error fetching contributors for repository latexstuff: list index out of range\n",
      "Error fetching contributors for repository Differentation-Circuitx: list index out of range\n",
      "Error fetching contributors for repository Q-IQ: list index out of range\n",
      "Error fetching contributors for repository Q-IQ: list index out of range\n",
      "Error fetching contributors for repository dungeon: list index out of range\n",
      "Error fetching contributors for repository pdf-ai: list index out of range\n",
      "Error fetching contributors for repository ChatBot: list index out of range\n",
      "Error fetching contributors for repository Optimal-Path: list index out of range\n",
      "Error fetching contributors for repository kuangbiao: list index out of range\n",
      "Error fetching contributors for repository Cozumel-Dental-health: list index out of range\n",
      "Error fetching contributors for repository dqn-car-racing: list index out of range\n",
      "Error fetching contributors for repository STM32H745ZIQ: list index out of range\n",
      "Error fetching contributors for repository chatgpt-knowledge: list index out of range\n",
      "Error fetching contributors for repository ST_QLearning: list index out of range\n",
      "Error fetching contributors for repository snake_Q_learning: list index out of range\n",
      "Error fetching contributors for repository backslashl: list index out of range\n",
      "Error fetching contributors for repository backslashl: list index out of range\n",
      "Error fetching contributors for repository q-learning-tic-tac-toe: list index out of range\n",
      "Error fetching contributors for repository AI-arena-pygame: list index out of range\n",
      "Error fetching contributors for repository q-sys-plugin-inogeni-toggle: list index out of range\n",
      "Data exported to repos2023.csv and repos2023.xlsx successfully.\n"
     ]
    }
   ],
   "source": [
    "from github import Github\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "access_token = \"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\"\n",
    "\n",
    "# Create a GitHub instance and authenticate\n",
    "g = Github(access_token)\n",
    "\n",
    "# Retrieve repositories created during the year 2023\n",
    "repositories = g.search_repositories(query='created:2023')\n",
    "\n",
    "# Extract information from each repository\n",
    "extracted_data = []\n",
    "for repo in repositories:\n",
    "    name = repo.name\n",
    "    url = repo.html_url\n",
    "\n",
    "    try:\n",
    "        contributors = [contributor.login for contributor in repo.get_contributors()[:5]]\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching contributors for repository {name}: {str(e)}\")\n",
    "        contributors = []\n",
    "\n",
    "    issues_count = repo.open_issues_count\n",
    "    forks_count = repo.forks_count\n",
    "    languages = list(repo.get_languages().keys())\n",
    "    stars = repo.stargazers_count\n",
    "\n",
    "    extracted_data.append({'Name': name, 'URL': url, 'Contributors': ', '.join(contributors),\n",
    "                           'Issues Count': issues_count, 'Forks Count': forks_count,\n",
    "                           'Languages': ', '.join(languages), 'Stars': stars})\n",
    "\n",
    "while repositories._couldGrow():\n",
    "    repositories = repositories._grow()\n",
    "    for repo in repositories:\n",
    "        name = repo.name\n",
    "        url = repo.html_url\n",
    "\n",
    "        try:\n",
    "            contributors = [contributor.login for contributor in repo.get_contributors()[:5]]\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching contributors for repository {name}: {str(e)}\")\n",
    "            contributors = []\n",
    "\n",
    "        issues_count = repo.open_issues_count\n",
    "        forks_count = repo.forks_count\n",
    "        languages = list(repo.get_languages().keys())\n",
    "        stars = repo.stargazers_count\n",
    "\n",
    "        extracted_data.append({'Name': name, 'URL': url, 'Contributors': ', '.join(contributors),\n",
    "                               'Issues Count': issues_count, 'Forks Count': forks_count,\n",
    "                               'Languages': ', '.join(languages), 'Stars': stars})\n",
    "\n",
    "df = pd.DataFrame(extracted_data)\n",
    "\n",
    "csv_file_path = 'repos2023.csv'\n",
    "excel_file_path = 'repos2023.xlsx'\n",
    "\n",
    "df.to_csv(csv_file_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "# Write the data to the Excel file\n",
    "df.to_excel(excel_file_path, index=False)\n",
    "\n",
    "print(f\"Data exported to {csv_file_path} and {excel_file_path} successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1564d228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: 422 Client Error: Unprocessable Entity for url: https://api.github.com/search/repositories?q=created%3A2023&per_page=100&page=11\n",
      "Number of rows: 1000\n",
      "Data exported to repositories.csv and repositories.xlsx successfully.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "username = 'omardbaa'\n",
    "access_token = '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'\n",
    "\n",
    "\n",
    "base_url = 'https://api.github.com'\n",
    "query_params = {\n",
    "    'q': 'created:2023',\n",
    "    'per_page': 100,  \n",
    "    'page': 1 \n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'Authorization': f'Token {access_token}',\n",
    "    'Accept': 'application/vnd.github.v3+json'\n",
    "}\n",
    "\n",
    "extracted_data = []\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        response = requests.get(f'{base_url}/search/repositories', headers=headers, params=query_params, timeout=300)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        if 'items' not in data or len(data['items']) == 0:\n",
    "            break\n",
    "\n",
    "        for item in data['items']:\n",
    "            repository = item['full_name']\n",
    "            url = item['html_url']\n",
    "            description = item['description']\n",
    "            stars = item['stargazers_count']\n",
    "            forks = item['forks_count']\n",
    "            issues = item['open_issues_count']\n",
    "            language = item['language']\n",
    "\n",
    "            extracted_data.append({'Repository': repository, 'URL': url, 'Description': description, 'Stars': stars, 'Forks': forks, 'Issues': issues, 'Language': language})\n",
    "\n",
    "        query_params['page'] += 1\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        break\n",
    "\n",
    "df = pd.DataFrame(extracted_data)\n",
    "\n",
    "csv_file_path = 'repositories.csv'\n",
    "excel_file_path = 'repositories.xlsx'\n",
    "\n",
    "df.to_csv(csv_file_path, index=False, encoding='utf-8-sig')\n",
    "df.to_excel(excel_file_path, index=False)\n",
    "\n",
    "row_count = len(df)\n",
    "print(f\"Number of rows: {row_count}\")\n",
    "\n",
    "print(f\"Data exported to {csv_file_path} and {excel_file_path} successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce314f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for Day 1...\n",
      "An error occurred: 422 Client Error: Unprocessable Entity for url: https://api.github.com/search/repositories?q=created%3A%3E2023-01-01T00%3A00%3A00Z&per_page=100&page=11&sort=stars&order=desc\n",
      "Fetching data for Day 2...\n",
      "An error occurred: 422 Client Error: Unprocessable Entity for url: https://api.github.com/search/repositories?q=created%3A%3E2023-01-01T00%3A00%3A00Z&per_page=100&page=11&sort=stars&order=desc\n",
      "Fetching data for Day 3...\n",
      "An error occurred: 422 Client Error: Unprocessable Entity for url: https://api.github.com/search/repositories?q=created%3A%3E2023-01-01T00%3A00%3A00Z&per_page=100&page=11&sort=stars&order=desc\n",
      "Fetching data for Day 4...\n",
      "An error occurred: 422 Client Error: Unprocessable Entity for url: https://api.github.com/search/repositories?q=created%3A%3E2023-01-01T00%3A00%3A00Z&per_page=100&page=11&sort=stars&order=desc\n",
      "Fetching data for Day 5...\n",
      "An error occurred: 422 Client Error: Unprocessable Entity for url: https://api.github.com/search/repositories?q=created%3A%3E2023-01-01T00%3A00%3A00Z&per_page=100&page=11&sort=stars&order=desc\n",
      "Fetching data for Day 6...\n",
      "An error occurred: 422 Client Error: Unprocessable Entity for url: https://api.github.com/search/repositories?q=created%3A%3E2023-01-01T00%3A00%3A00Z&per_page=100&page=11&sort=stars&order=desc\n",
      "Fetching data for Day 7...\n",
      "An error occurred: 422 Client Error: Unprocessable Entity for url: https://api.github.com/search/repositories?q=created%3A%3E2023-01-01T00%3A00%3A00Z&per_page=100&page=11&sort=stars&order=desc\n",
      "Fetching data for Day 8...\n",
      "An error occurred: 422 Client Error: Unprocessable Entity for url: https://api.github.com/search/repositories?q=created%3A%3E2023-01-01T00%3A00%3A00Z&per_page=100&page=11&sort=stars&order=desc\n",
      "Fetching data for Day 9...\n",
      "An error occurred: 422 Client Error: Unprocessable Entity for url: https://api.github.com/search/repositories?q=created%3A%3E2023-01-01T00%3A00%3A00Z&per_page=100&page=11&sort=stars&order=desc\n",
      "Fetching data for Day 10...\n",
      "An error occurred: 422 Client Error: Unprocessable Entity for url: https://api.github.com/search/repositories?q=created%3A%3E2023-01-01T00%3A00%3A00Z&per_page=100&page=11&sort=stars&order=desc\n",
      "Fetching data for Day 11...\n",
      "An error occurred: 422 Client Error: Unprocessable Entity for url: https://api.github.com/search/repositories?q=created%3A%3E2023-01-01T00%3A00%3A00Z&per_page=100&page=11&sort=stars&order=desc\n",
      "Fetching data for Day 12...\n",
      "An error occurred: 422 Client Error: Unprocessable Entity for url: https://api.github.com/search/repositories?q=created%3A%3E2023-01-01T00%3A00%3A00Z&per_page=100&page=11&sort=stars&order=desc\n",
      "Fetching data for Day 13...\n",
      "An error occurred: 422 Client Error: Unprocessable Entity for url: https://api.github.com/search/repositories?q=created%3A%3E2023-01-01T00%3A00%3A00Z&per_page=100&page=11&sort=stars&order=desc\n",
      "Fetching data for Day 14...\n",
      "An error occurred: 422 Client Error: Unprocessable Entity for url: https://api.github.com/search/repositories?q=created%3A%3E2023-01-01T00%3A00%3A00Z&per_page=100&page=11&sort=stars&order=desc\n",
      "Fetching data for Day 15...\n",
      "An error occurred: 422 Client Error: Unprocessable Entity for url: https://api.github.com/search/repositories?q=created%3A%3E2023-01-01T00%3A00%3A00Z&per_page=100&page=11&sort=stars&order=desc\n",
      "Fetching data for Day 16...\n",
      "An error occurred: 422 Client Error: Unprocessable Entity for url: https://api.github.com/search/repositories?q=created%3A%3E2023-01-01T00%3A00%3A00Z&per_page=100&page=11&sort=stars&order=desc\n",
      "Fetching data for Day 17...\n",
      "An error occurred: 422 Client Error: Unprocessable Entity for url: https://api.github.com/search/repositories?q=created%3A%3E2023-01-01T00%3A00%3A00Z&per_page=100&page=11&sort=stars&order=desc\n",
      "Fetching data for Day 18...\n",
      "An error occurred: 422 Client Error: Unprocessable Entity for url: https://api.github.com/search/repositories?q=created%3A%3E2023-01-01T00%3A00%3A00Z&per_page=100&page=11&sort=stars&order=desc\n",
      "Fetching data for Day 19...\n",
      "An error occurred: 422 Client Error: Unprocessable Entity for url: https://api.github.com/search/repositories?q=created%3A%3E2023-01-01T00%3A00%3A00Z&per_page=100&page=11&sort=stars&order=desc\n",
      "Fetching data for Day 20...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "username = 'omardbaa'\n",
    "access_token = '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'\n",
    "\n",
    "base_url = 'https://api.github.com/search/repositories'\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {access_token}',\n",
    "    'Accept': 'application/vnd.github.v3+json'\n",
    "}\n",
    "\n",
    "start_date = '2023-01-01'\n",
    "num_days = 30\n",
    "per_page = 100\n",
    "query_params = {\n",
    "    'q': f'created:>{start_date}',\n",
    "    'per_page': per_page,\n",
    "    'page': 1,\n",
    "    'sort': 'stars',\n",
    "    'order': 'desc'\n",
    "}\n",
    "\n",
    "extracted_data = []\n",
    "\n",
    "for day in range(num_days):\n",
    "    print(f\"Fetching data for Day {day+1}...\")\n",
    "    query_params['q'] = f'created:>{start_date}T00:00:00Z'\n",
    "    query_params['page'] = 1\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            response = requests.get(base_url, headers=headers, params=query_params, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "\n",
    "            if 'items' not in data or len(data['items']) == 0:\n",
    "                break\n",
    "\n",
    "            for item in data['items']:\n",
    "                repository = item['full_name']\n",
    "                url = item['html_url']\n",
    "                description = item['description']\n",
    "                stars = item['stargazers_count']\n",
    "                forks = item['forks_count']\n",
    "                issues = item['open_issues_count']\n",
    "                language = item['language']\n",
    "\n",
    "                extracted_data.append({'Repository': repository, 'URL': url, 'Description': description, 'Stars': stars, 'Forks': forks, 'Issues': issues, 'Language': language})\n",
    "\n",
    "            query_params['page'] += 1\n",
    "\n",
    "            # Pause for a few seconds between requests to avoid hitting API rate limits\n",
    "            time.sleep(5)\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"An error occurred: {str(e)}\")\n",
    "            break\n",
    "\n",
    "df = pd.DataFrame(extracted_data)\n",
    "\n",
    "csv_file_path = 'repositories.csv'\n",
    "excel_file_path = 'repositories.xlsx'\n",
    "\n",
    "df.to_csv(csv_file_path, index=False, encoding='utf-8-sig')\n",
    "df.to_excel(excel_file_path, index=False)\n",
    "\n",
    "row_count = len(df)\n",
    "print(f\"Number of rows: {row_count}\")\n",
    "\n",
    "print(f\"Data exported to {csv_file_path} and {excel_file_path} successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56b747b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for Day 1...\n",
      "An error occurred: 422 Client Error: Unprocessable Entity for url: https://api.github.com/search/repositories?q=created%3A%3E2023-05-01&per_page=100&sort=stars&order=desc&page=11\n",
      "Fetching data for Day 2...\n",
      "An error occurred: 422 Client Error: Unprocessable Entity for url: https://api.github.com/search/repositories?q=created%3A%3E2023-05-02&per_page=100&sort=stars&order=desc&page=11\n",
      "Number of non-duplicated rows: 2000\n",
      "Data exported to repositories.csv and repositories.xlsx successfully.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "username = 'omardbaa'\n",
    "access_token = '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'\n",
    "\n",
    "base_url = 'https://api.github.com/search/repositories'\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {access_token}',\n",
    "    'Accept': 'application/vnd.github.v3+json'\n",
    "}\n",
    "\n",
    "start_date = '2023-05-01'\n",
    "num_days = 2\n",
    "per_page = 100\n",
    "query_params = {\n",
    "    'q': f'created:>{start_date}',\n",
    "    'per_page': per_page,\n",
    "    'sort': 'stars',\n",
    "    'order': 'desc'\n",
    "}\n",
    "\n",
    "extracted_data = []\n",
    "\n",
    "for day in range(num_days):\n",
    "    print(f\"Fetching data for Day {day+1}...\")\n",
    "    query_params['page'] = 1\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            response = requests.get(base_url, headers=headers, params=query_params, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "\n",
    "            if 'items' not in data or len(data['items']) == 0:\n",
    "                break\n",
    "\n",
    "            for item in data['items']:\n",
    "                repository = item['full_name']\n",
    "                url = item['html_url']\n",
    "                description = item['description']\n",
    "                stars = item['stargazers_count']\n",
    "                forks = item['forks_count']\n",
    "                issues = item['open_issues_count']\n",
    "                language = item['language']\n",
    "\n",
    "                extracted_data.append({'Repository': repository, 'URL': url, 'Description': description, 'Stars': stars, 'Forks': forks, 'Issues': issues, 'Language': language})\n",
    "\n",
    "            query_params['page'] += 1\n",
    "\n",
    "            time.sleep(5)\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"An error occurred: {str(e)}\")\n",
    "            break\n",
    "\n",
    "    start_date = (pd.to_datetime(start_date) + pd.DateOffset(days=1)).strftime('%Y-%m-%d')\n",
    "    query_params['q'] = f'created:>{start_date}'\n",
    "\n",
    "df = pd.DataFrame(extracted_data)\n",
    "\n",
    "\n",
    "row_count = len(df)\n",
    "print(f\"Number of non-duplicated rows: {row_count}\")\n",
    "\n",
    "csv_file_path = 'repositories.csv'\n",
    "excel_file_path = 'repositories.xlsx'\n",
    "\n",
    "df.to_csv(csv_file_path, index=False, encoding='utf-8-sig')\n",
    "df.to_excel(excel_file_path, index=False)\n",
    "\n",
    "print(f\"Data exported to {csv_file_path} and {excel_file_path} successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a75bdf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'omardbaa'\n",
    "access_token = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73b0f15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for Day 1...\n",
      "An error occurred: 422 Client Error: Unprocessable Entity for url: https://api.github.com/search/repositories?q=created%3A%3E2023-05-01&per_page=100&sort=stars&order=desc&page=11\n",
      "Fetching data for Day 2...\n",
      "An error occurred: 422 Client Error: Unprocessable Entity for url: https://api.github.com/search/repositories?q=created%3A%3E2023-05-02&per_page=100&sort=stars&order=desc&page=11\n",
      "Fetching data for Day 3...\n",
      "An error occurred: 422 Client Error: Unprocessable Entity for url: https://api.github.com/search/repositories?q=created%3A%3E2023-05-03&per_page=100&sort=stars&order=desc&page=11\n",
      "Number of non-duplicated rows: 1077\n",
      "Data exported to repositories.csv and repositories.xlsx successfully.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "base_url = 'https://api.github.com/search/repositories'\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {access_token}',\n",
    "    'Accept': 'application/vnd.github.v3+json'\n",
    "}\n",
    "\n",
    "start_date = '2023-05-01'\n",
    "num_days = 3\n",
    "per_page = 100\n",
    "query_params = {\n",
    "    'q': f'created:>{start_date}',\n",
    "    'per_page': per_page,\n",
    "    'sort': 'stars',\n",
    "    'order': 'desc'\n",
    "}\n",
    "\n",
    "extracted_data = set()  # Use a set to store non-duplicated data\n",
    "\n",
    "for day in range(num_days):\n",
    "    print(f\"Fetching data for Day {day+1}...\")\n",
    "    query_params['page'] = 1\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            response = requests.get(base_url, headers=headers, params=query_params, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "\n",
    "            if 'items' not in data or len(data['items']) == 0:\n",
    "                break\n",
    "\n",
    "            for item in data['items']:\n",
    "                repository = item['full_name']\n",
    "                url = item['html_url']\n",
    "                description = item['description']\n",
    "                stars = item['stargazers_count']\n",
    "                forks = item['forks_count']\n",
    "                issues = item['open_issues_count']\n",
    "                language = item['language']\n",
    "\n",
    "                extracted_data.add((repository, url, description, stars, forks, issues, language))\n",
    "\n",
    "            query_params['page'] += 1\n",
    "\n",
    "            time.sleep(5)\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"An error occurred: {str(e)}\")\n",
    "            break\n",
    "\n",
    "    start_date = (pd.to_datetime(start_date) + pd.DateOffset(days=1)).strftime('%Y-%m-%d')\n",
    "    query_params['q'] = f'created:>{start_date}'\n",
    "\n",
    "# Convert the set of tuples to a list of dictionaries\n",
    "extracted_data = [\n",
    "    {'Repository': repo, 'URL': url, 'Description': desc, 'Stars': stars, 'Forks': forks, 'Issues': issues, 'Language': lang}\n",
    "    for repo, url, desc, stars, forks, issues, lang in extracted_data\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(extracted_data)\n",
    "\n",
    "row_count = len(df)\n",
    "print(f\"Number of non-duplicated rows: {row_count}\")\n",
    "\n",
    "csv_file_path = 'repositories.csv'\n",
    "excel_file_path = 'repositories.xlsx'\n",
    "\n",
    "df.to_csv(csv_file_path, index=False, encoding='utf-8-sig')\n",
    "df.to_excel(excel_file_path, index=False)\n",
    "\n",
    "print(f\"Data exported to {csv_file_path} and {excel_file_path} successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "046e8e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1461.0\n"
     ]
    }
   ],
   "source": [
    "print(365.25*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "655e4f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 1: Extracted 500 rows in 0:00:14.436937\n",
      "Day 2: Extracted 500 rows in 0:00:14.318417\n",
      "Day 3: Extracted 500 rows in 0:00:15.169040\n",
      "Day 4: Extracted 500 rows in 0:00:14.015947\n",
      "Day 5: Extracted 500 rows in 0:00:14.034839\n",
      "Day 6: Extracted 500 rows in 0:00:14.872829\n",
      "Day 7: Extracted 500 rows in 0:00:15.454762\n",
      "Day 8: Extracted 500 rows in 0:00:15.248799\n",
      "Day 9: Extracted 500 rows in 0:00:14.757725\n",
      "Day 10: Extracted 500 rows in 0:00:14.009634\n",
      "Day 11: Extracted 500 rows in 0:00:15.144564\n",
      "Day 12: Extracted 500 rows in 0:00:14.444195\n",
      "Day 13: Extracted 500 rows in 0:00:14.236996\n",
      "Day 14: Extracted 500 rows in 0:00:14.456851\n",
      "Day 15: Extracted 500 rows in 0:00:14.116011\n",
      "Day 16: Extracted 500 rows in 0:00:17.512918\n",
      "Day 17: Extracted 500 rows in 0:00:15.352903\n",
      "Day 18: Extracted 500 rows in 0:00:15.769559\n",
      "Day 19: Extracted 500 rows in 0:00:13.519005\n",
      "Day 20: Extracted 500 rows in 0:00:14.752320\n",
      "Day 21: Extracted 500 rows in 0:00:15.574189\n",
      "Day 22: Extracted 500 rows in 0:00:14.529985\n",
      "Day 23: Extracted 500 rows in 0:00:14.323189\n",
      "Day 24: Extracted 500 rows in 0:00:15.367359\n",
      "Day 25: Extracted 500 rows in 0:00:15.780398\n",
      "Day 26: Extracted 500 rows in 0:00:15.453218\n",
      "Day 27: Extracted 500 rows in 0:00:14.131414\n",
      "Day 28: Extracted 500 rows in 0:00:15.263464\n",
      "Day 29: Extracted 500 rows in 0:00:14.126730\n",
      "Day 30: Extracted 500 rows in 0:00:13.751974\n",
      "Day 31: Extracted 500 rows in 0:00:13.892774\n",
      "Day 32: Extracted 500 rows in 0:00:14.855286\n",
      "Day 33: Extracted 500 rows in 0:00:13.822609\n",
      "Day 34: Extracted 500 rows in 0:00:13.721840\n",
      "Day 35: Extracted 500 rows in 0:00:13.927131\n",
      "Day 36: Extracted 500 rows in 0:00:14.649717\n",
      "Day 37: Extracted 500 rows in 0:00:15.874037\n",
      "Day 38: Extracted 500 rows in 0:00:13.610074\n",
      "Day 39: Extracted 500 rows in 0:00:14.951142\n",
      "Day 40: Extracted 500 rows in 0:00:16.283845\n",
      "Day 41: Extracted 500 rows in 0:00:14.434894\n",
      "Day 42: Extracted 500 rows in 0:00:15.266075\n",
      "Day 43: Extracted 500 rows in 0:00:13.319419\n",
      "Day 44: Extracted 500 rows in 0:00:14.637613\n",
      "Day 45: Extracted 500 rows in 0:00:14.845748\n",
      "Day 46: Extracted 500 rows in 0:00:12.895094\n",
      "Day 47: Extracted 500 rows in 0:00:12.917160\n",
      "Day 48: Extracted 500 rows in 0:00:14.626754\n",
      "Day 49: Extracted 500 rows in 0:00:14.455163\n",
      "Day 50: Extracted 500 rows in 0:00:13.403386\n",
      "Day 51: Extracted 500 rows in 0:00:13.316192\n",
      "Day 52: Extracted 500 rows in 0:00:13.404901\n",
      "Day 53: Extracted 500 rows in 0:00:13.831974\n",
      "Day 54: Extracted 500 rows in 0:00:13.202685\n",
      "Day 55: Extracted 500 rows in 0:00:14.235716\n",
      "Day 56: Extracted 500 rows in 0:00:12.104503\n",
      "Day 57: Extracted 500 rows in 0:00:13.718317\n",
      "Day 58: Extracted 500 rows in 0:00:13.605491\n",
      "Day 59: Extracted 500 rows in 0:00:13.109252\n",
      "Day 60: Extracted 500 rows in 0:00:12.789205\n",
      "Day 61: Extracted 500 rows in 0:00:13.633674\n",
      "Day 62: Extracted 500 rows in 0:00:13.612674\n",
      "Day 63: Extracted 500 rows in 0:00:13.323828\n",
      "Day 64: Extracted 500 rows in 0:00:14.328642\n",
      "Day 65: Extracted 500 rows in 0:00:14.126571\n",
      "Day 66: Extracted 500 rows in 0:00:15.183097\n",
      "Day 67: Extracted 500 rows in 0:00:13.821728\n",
      "Day 68: Extracted 500 rows in 0:00:12.999824\n",
      "Day 69: Extracted 500 rows in 0:00:12.684778\n",
      "Day 70: Extracted 500 rows in 0:00:13.920356\n",
      "Day 71: Extracted 500 rows in 0:00:12.711479\n",
      "Day 72: Extracted 500 rows in 0:00:13.613030\n",
      "Day 73: Extracted 500 rows in 0:00:13.720731\n",
      "Day 74: Extracted 500 rows in 0:00:13.614283\n",
      "Day 75: Extracted 500 rows in 0:00:13.730837\n",
      "Day 76: Extracted 500 rows in 0:00:15.255499\n",
      "Day 77: Extracted 500 rows in 0:00:13.409903\n",
      "Day 78: Extracted 500 rows in 0:00:12.491803\n",
      "Day 79: Extracted 500 rows in 0:00:14.346804\n",
      "Day 80: Extracted 500 rows in 0:00:13.409228\n",
      "Day 81: Extracted 500 rows in 0:00:13.311246\n",
      "Day 82: Extracted 500 rows in 0:00:12.903553\n",
      "Day 83: Extracted 500 rows in 0:00:12.605563\n",
      "Day 84: Extracted 500 rows in 0:00:13.616804\n",
      "Day 85: Extracted 500 rows in 0:00:13.605929\n",
      "Day 86: Extracted 500 rows in 0:00:12.804838\n",
      "Day 87: Extracted 500 rows in 0:00:13.931620\n",
      "Day 88: Extracted 500 rows in 0:00:12.394884\n",
      "Day 89: Extracted 500 rows in 0:00:13.600777\n",
      "Day 90: Extracted 500 rows in 0:00:14.764762\n",
      "Day 91: Extracted 500 rows in 0:00:14.531703\n",
      "Day 92: Extracted 500 rows in 0:00:13.125453\n",
      "Day 93: Extracted 500 rows in 0:00:14.007853\n",
      "Day 94: Extracted 500 rows in 0:00:11.781886\n",
      "Day 95: Extracted 500 rows in 0:00:14.845410\n",
      "Day 96: Extracted 500 rows in 0:00:12.797998\n",
      "Day 97: Extracted 500 rows in 0:00:14.131425\n",
      "Day 98: Extracted 500 rows in 0:00:13.725317\n",
      "Day 99: Extracted 500 rows in 0:00:13.004855\n",
      "Day 100: Extracted 500 rows in 0:00:17.507218\n",
      "Day 101: Extracted 500 rows in 0:00:13.818904\n",
      "Day 102: Extracted 500 rows in 0:00:13.412580\n",
      "Day 103: Extracted 500 rows in 0:00:13.319518\n",
      "Day 104: Extracted 500 rows in 0:00:15.255968\n",
      "Day 105: Extracted 500 rows in 0:00:14.546821\n",
      "Day 106: Extracted 500 rows in 0:00:13.414112\n",
      "Day 107: Extracted 500 rows in 0:00:13.409359\n",
      "Day 108: Extracted 500 rows in 0:00:15.256910\n",
      "Day 109: Extracted 500 rows in 0:00:13.936815\n",
      "Day 110: Extracted 500 rows in 0:00:13.204619\n",
      "Day 111: Extracted 500 rows in 0:00:13.415371\n",
      "Day 112: Extracted 500 rows in 0:00:13.109478\n",
      "Day 113: Extracted 500 rows in 0:00:13.515293\n",
      "Day 114: Extracted 500 rows in 0:00:12.899512\n",
      "Day 115: Extracted 500 rows in 0:00:12.610230\n",
      "Day 116: Extracted 500 rows in 0:00:13.512413\n",
      "Day 117: Extracted 500 rows in 0:00:13.002526\n",
      "Day 118: Extracted 500 rows in 0:00:13.308435\n",
      "Day 119: Extracted 500 rows in 0:00:14.138719\n",
      "Day 120: Extracted 500 rows in 0:00:13.720855\n",
      "Day 121: Extracted 500 rows in 0:00:14.841906\n",
      "Day 122: Extracted 500 rows in 0:00:13.644954\n",
      "Day 123: Extracted 500 rows in 0:00:14.335634\n",
      "Day 124: Extracted 500 rows in 0:00:13.801768\n",
      "Day 125: Extracted 500 rows in 0:00:12.592100\n",
      "Day 126: Extracted 500 rows in 0:00:13.836137\n",
      "Day 127: Extracted 500 rows in 0:00:13.401789\n",
      "Day 128: Extracted 500 rows in 0:00:13.209985\n",
      "Day 129: Extracted 500 rows in 0:00:12.607606\n",
      "Day 130: Extracted 500 rows in 0:00:13.914675\n",
      "Day 131: Extracted 500 rows in 0:00:14.235255\n",
      "Day 132: Extracted 500 rows in 0:00:15.563553\n",
      "Day 133: Extracted 500 rows in 0:00:14.128359\n",
      "Day 134: Extracted 500 rows in 0:00:14.128852\n",
      "Day 135: Extracted 500 rows in 0:00:14.544426\n",
      "Day 136: Extracted 500 rows in 0:00:12.699103\n",
      "Day 137: Extracted 500 rows in 0:00:13.517185\n",
      "Day 138: Extracted 500 rows in 0:00:13.112088\n",
      "Day 139: Extracted 500 rows in 0:00:13.931541\n",
      "Day 140: Extracted 500 rows in 0:00:13.706929\n",
      "Day 141: Extracted 500 rows in 0:00:13.528455\n",
      "Day 142: Extracted 500 rows in 0:00:13.426206\n",
      "Day 143: Extracted 500 rows in 0:00:14.616917\n",
      "Day 144: Extracted 500 rows in 0:00:14.039344\n",
      "Day 145: Extracted 500 rows in 0:00:13.817862\n",
      "Day 146: Extracted 500 rows in 0:00:13.322414\n",
      "Day 147: Extracted 598 rows in 0:00:15.659825\n",
      "Day 148: Extracted 499 rows in 0:00:12.693041\n",
      "Day 149: Extracted 500 rows in 0:00:13.010413\n",
      "Day 150: Extracted 499 rows in 0:00:12.999685\n",
      "Number of non-duplicated rows: 75096\n",
      "Data exported to repositories.csv and repositories.xlsx successfully.\n",
      "Total rows extracted: 75096\n",
      "Total time taken: 0:34:56.248476\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "\n",
    "username = 'omardbaa'\n",
    "access_token = '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'\n",
    "\n",
    "# GitHub API base URL\n",
    "base_url = 'https://api.github.com'\n",
    "\n",
    "# Number of repositories per day\n",
    "repositories_per_day = 500\n",
    "\n",
    "# Number of days to scrape  \n",
    "days_to_scrape = 150\n",
    "\n",
    "# Calculate the start and end dates for scraping\n",
    "end_date = datetime.now().date()\n",
    "start_date = end_date - timedelta(days=days_to_scrape)\n",
    "\n",
    "# Initialize the repositories list\n",
    "repositories = []\n",
    "\n",
    "# Retry mechanism for API requests\n",
    "retry_strategy = Retry(\n",
    "    total=3,\n",
    "    backoff_factor=0.5,\n",
    "    status_forcelist=[429, 500, 502, 503, 504],\n",
    "    allowed_methods=[\"GET\"],\n",
    ")\n",
    "adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "http = requests.Session()\n",
    "http.mount(\"https://\", adapter)\n",
    "\n",
    "# Variables for tracking total rows and time taken\n",
    "total_rows = 0\n",
    "total_time = timedelta()\n",
    "\n",
    "# Iterate over each day\n",
    "for day in range(days_to_scrape):\n",
    "    current_date = start_date + timedelta(days=day)\n",
    "    formatted_date = current_date.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Fetch repositories using pagination\n",
    "    page = 1\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    while len(repositories) < repositories_per_day * (day + 1):\n",
    "        # Create the API URL to fetch repositories created on the current day and specific page\n",
    "        url = f'{base_url}/search/repositories?q=created:{formatted_date}&sort=stars&order=desc&per_page=100&page={page}'\n",
    "\n",
    "        # Make the API request with retry logic\n",
    "        headers = {'Authorization': f'token {access_token}'} if access_token else {}\n",
    "        response = http.get(url, headers=headers)\n",
    "        data = response.json()\n",
    "\n",
    "        if 'items' in data:\n",
    "            # Extract repository information from the response\n",
    "            items = data['items']\n",
    "            sorted_items = sorted(items, key=lambda item: item['stargazers_count'], reverse=True)\n",
    "\n",
    "            for item in sorted_items[:repositories_per_day]:\n",
    "                repository = {\n",
    "                    'id': item['id'],\n",
    "                    'full_name': item['full_name'],\n",
    "                    'url': item['html_url'],\n",
    "                    'stargazers_count': item['stargazers_count'],\n",
    "                    'language': item.get('language', ''),\n",
    "                    'license': item['license']['name'] if item['license'] else '',\n",
    "                    'topics': item.get('topics', []),\n",
    "                    'forks': item['forks'],\n",
    "                    'issues_count': item['open_issues_count'],\n",
    "                    'year': current_date.year,\n",
    "                    'watchers_count': item['watchers_count'],  # Number of watchers\n",
    "                    'created_at': item['created_at'],  # Date and time of repository creation\n",
    "                }\n",
    "\n",
    "                repositories.append(repository)\n",
    "\n",
    "        page += 1\n",
    "\n",
    "        if 'next' not in response.links:\n",
    "            break\n",
    "\n",
    "    end_time = datetime.now()\n",
    "    time_taken = end_time - start_time\n",
    "    total_time += time_taken\n",
    "\n",
    "    rows_extracted = len(repositories) - total_rows\n",
    "    total_rows = len(repositories)\n",
    "    print(f\"Day {day + 1}: Extracted {rows_extracted} rows in {time_taken}\")\n",
    "\n",
    "# Convert the repositories list to a DataFrame\n",
    "df = pd.DataFrame(repositories)\n",
    "\n",
    "# Select the desired columns\n",
    "df = df[['id', 'full_name', 'url', 'stargazers_count', 'language', 'license', 'topics',\n",
    "         'forks', 'issues_count', 'year', 'watchers_count', 'created_at']]\n",
    "\n",
    "row_count = len(df)\n",
    "print(f\"Number of non-duplicated rows: {row_count}\")\n",
    "\n",
    "csv_file_path = 'repositories.csv'\n",
    "excel_file_path = 'repositories.xlsx'\n",
    "\n",
    "df.to_csv(csv_file_path, index=False, encoding='utf-8-sig')\n",
    "df.to_excel(excel_file_path, index=False)\n",
    "\n",
    "print(f\"Data exported to {csv_file_path} and {excel_file_path} successfully.\")\n",
    "print(f\"Total rows extracted: {total_rows}\")\n",
    "print(f\"Total time taken: {total_time}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
